{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75e6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos re para expresiones regulares\n",
    "import os\n",
    "import settings\n",
    "from preprocessor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66fc2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "028bb48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RAW_PATH = os.path.join(settings.DATA_RAW_DIR,'PunctuationTask.test.en')\n",
    "CHECK_RAW_PATH = os.path.join(settings.DATA_RAW_DIR,'PunctuationTask.check.en')\n",
    "TRAIN_RAW_PATH = os.path.join(settings.DATA_RAW_DIR,'PunctuationTask.train.en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec49d2c",
   "metadata": {},
   "source": [
    "### APARTADO 1\n",
    "\n",
    "Vamos a implementar un sistema que reciba una expresión como entrada (será una expresión formada solo por minúsculas y sin los signos de puntuación mencionados) y la salida será la misma expresión pero con los cambios correspondientes a la introducción de mayúsculas y signos de puntuación indicados.\n",
    "\n",
    "Como primera versión de esta función addPunctuationBasic se implementará un modelo que\n",
    "simplemente cambia la primera letra por mayúscula y añade al final del string de entrada un punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a142e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from punctuator_basic import addPunctuationBasic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763b8a98",
   "metadata": {},
   "source": [
    "Vemos que la función anterior realiza la operación correctamente con el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25868085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Esta es una frase de prueba.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addPunctuationBasic('esta es una frase de prueba')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb097359",
   "metadata": {},
   "source": [
    "### APARTADO 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da97fae",
   "metadata": {},
   "source": [
    "Antes de definir la función verifyPuntuation vamos a definir dos funciones auxiliares que nos servirán.\n",
    "* padding(list1,list2): Devuelve las los listas de entrada de forma que ambas tengan la misma longitud, añadiendo el elemento string vacío ('') a la lista de menor longitud.\n",
    "\n",
    "* tokenizer(text): tokeniza el texto de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8162c1",
   "metadata": {},
   "source": [
    "Veamos su funcionamiento con el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a2ce2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista 1 con padding:  ['s', 'a', '', ''] \t Lista 2 con padding:  ['1', '2', '3', '4']\n",
      "Las longitudes son iguales:  True\n"
     ]
    }
   ],
   "source": [
    "list1, list2 = ['s','a'], ['1','2','3','4']\n",
    "l1, l2 = padding(list1,list2)\n",
    "print('Lista 1 con padding: ',l1,'\\t Lista 2 con padding: ', l2)\n",
    "print('Las longitudes son iguales: ', len(l1) == len(l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf854a0",
   "metadata": {},
   "source": [
    "Veamos cómo funciona con el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d12cf027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sara', 'said', ':', 'Hello', ',', \"what's\", 'your', 'name', '?']\n"
     ]
    }
   ],
   "source": [
    "text_example= \"Sara said: Hello, what's your name?\"\n",
    "print(tokenizer(text_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80814bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluator import verifyPunctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5fbedc",
   "metadata": {},
   "source": [
    "Utilicemos el ejemplo del documento para ver si funciona correctamente la función. Además verificamos que intercambiar check y test devuelve el mismo número de elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f21d9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check vs test:  {('D', 1), ('S', 2), ('I', 4)}\n",
      "test vs check:  {('S', 1), ('I', 1), ('D', 3)}\n"
     ]
    }
   ],
   "source": [
    "check_example = \"Hello. What's your name?\"\n",
    "test_example = \"Hello what's your, name?\"\n",
    "print('check vs test: ', verifyPunctuation(check_example,test_example))\n",
    "print('test vs check: ', verifyPunctuation(test_example,check_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c3077",
   "metadata": {},
   "source": [
    "### APARTADO 3\n",
    "\n",
    "Implementaremos una herramienta que permita recorrer todo el corpus de test y verificación. Es decir, irá recorriendo una a una las líneas de cada fichero (que están alineadas), aplicaría sobre la frase de test el algoritmo básico de puntuación (apartado 1: addPunctuationBasic() ) y a continuación comprobaría si el resultado es o no correcto usando la función verifyPunctuation() del apartado 2.\n",
    "\n",
    "En primer lugar vamos a definir una función evaluate_example que calcula las métricas precision y recall dado una instancia (check,test). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6771be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluator import evaluate_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638bf505",
   "metadata": {},
   "source": [
    "Comprobamos el funcionamiento de la función con el siguiente ejemplo.\n",
    "\n",
    "* check = \"Hello. What's your name?\"\n",
    "* test = \"hello what's your name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a7de147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LINE: \n",
      "  hello what's your name\n",
      "MODEL PUNCTUATED LINE: \n",
      "  Hello what's your name.\n",
      "VALIDATION LINE: \n",
      "  Hello. What's your name? \n",
      "\n",
      "Modificaciones necesarias:  {('S', 0), ('S', 1), ('I', 1), ('I', 4)}\n",
      "Modificaciones hechas por el modelo:  {('S', 0), ('I', 4)}\n",
      "Diferencias entre modelo y validación:  {('S', 1), ('I', 1), ('S', 4)} \n",
      "\n",
      "n_hechas (Núm. de modificaciones hechas por el modelo):  2\n",
      "n_correctas (Núm. de modificaciones correctas: \n",
      " interseccion(hechas,necesarias) - error de sustitucion de signo):  1\n",
      "n_necesarias (Núm. de modificaciones necesarias):  4 \n",
      "\n",
      "precision (n_correctas/n_hechas):  0.5\n",
      "recall (n_correctas/n_necesarias):  0.25 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.5, 0.25, 2, 1, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_example = \"Hello. What's your name?\"\n",
    "test_example = \"hello what's your name\"\n",
    "evaluate_example(addPunctuationBasic,check_example,test_example,print_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c460dae",
   "metadata": {},
   "source": [
    "Notemos que la oración puntuada es \"Hello what's your name.\", por lo que la función de validación va a considerar como correcto el haber insertado en el token 4, lo que se observa como ('I', 4) tanto en las modificaciones necesarias como las hechas por el modelo. Al no tener información sobre el caracter, esto podría dar lugar a un falso positivo, que es corregido correctamente con el error de sustitución de signo visto en la función.\n",
    "\n",
    "Definamos ahora la función evaluate(...) que raliza el proceso anterior para distintos corpus y calcula métricas gobales, es decir, la que pide el propio apartado 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2c034b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluator import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42740c1b",
   "metadata": {},
   "source": [
    "Evaluamos la función addPunctuationBasic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e40008f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "MÉTRICAS\n",
      "=============================================\n",
      "precision global:  0.9481749791028141\n",
      "recall global:  0.4281984334203655\n",
      "F1 global:  0.5899664102286271\n",
      "=============================================\n",
      "precision media:  0.9474342928660826\n",
      "recall medio:  0.5873733513179556\n",
      "F1 medio:  0.7251692521379949\n",
      "=============================================\n",
      "rendimiento:  0.263384786538729\n",
      "=============================================\n",
      "número de instancias en el corpus:  14382\n",
      "=============================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision_global': 0.9481749791028141,\n",
       " 'recall_global': 0.4281984334203655,\n",
       " 'F1_global': 0.5899664102286271,\n",
       " 'precision_mean': 0.9474342928660826,\n",
       " 'recall_mean': 0.5873733513179556,\n",
       " 'F1_mean': 0.7251692521379949,\n",
       " 'score': 0.263384786538729}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(addPunctuationBasic, check_file_path=CHECK_RAW_PATH, test_file_path=TEST_RAW_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cd307",
   "metadata": {},
   "source": [
    "Vemos que la precisión es alta, lo que indica que lo que tiene que hacer el modelo (poner la primera letra en mayúscula y un punto al final), lo hace bien. Sin embargo, el recall es relativamente bajo ya que esos cambios no son suficientes para puntuar correctamente las oraciones, cosa que también se deduce del bajo rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f6c1ac",
   "metadata": {},
   "source": [
    "Aunque no se pide, definimos la función evaluate_example_from_corpus que permite ver la información resultante de evaluate_example para un elemento en concreto del corpus dado el número de línea corpus_line. De esta forma podemos explorar y verificar el correcto funcionamiento de las funciones definidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edded325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluator import evaluate_example_from_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28b6cd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LINE: \n",
      "  and what do i mean by that\n",
      "MODEL PUNCTUATED LINE: \n",
      "  And what do i mean by that.\n",
      "VALIDATION LINE: \n",
      "  And what do I mean by that? \n",
      "\n",
      "Modificaciones necesarias:  {('S', 0), ('I', 7), ('S', 3)}\n",
      "Modificaciones hechas por el modelo:  {('S', 0), ('I', 7)}\n",
      "Diferencias entre modelo y validación:  {('S', 7), ('S', 3)} \n",
      "\n",
      "n_hechas (Núm. de modificaciones hechas por el modelo):  2\n",
      "n_correctas (Núm. de modificaciones correctas: \n",
      " interseccion(hechas,necesarias) - error de sustitucion de signo):  1\n",
      "n_necesarias (Núm. de modificaciones necesarias):  3 \n",
      "\n",
      "precision (n_correctas/n_hechas):  0.5\n",
      "recall (n_correctas/n_necesarias):  0.3333333333333333 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_example_from_corpus(addPunctuationBasic,check_file_path=CHECK_RAW_PATH,test_file_path=TEST_RAW_PATH ,corpus_line=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1614e4d2",
   "metadata": {},
   "source": [
    "### APARTADO 4\n",
    "\n",
    "Utilizando el corpus de entrenamiento contenido en PunctuationTask.train.en construimos un modelo de lenguaje inspirado en la idea de 4-gramas.\n",
    "\n",
    "Definimos una función auxiliar ngrams(text,N) que dado el string text devuelve la lista de N-gramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f67d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessor import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a8720",
   "metadata": {},
   "source": [
    "Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ca0d27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gramas de la oración:  Sara said: Hello! nice to meet you!\n",
      "\t [('Sara', 'said'), ('said', ':'), (':', 'Hello'), ('Hello', '!'), ('!', 'nice'), ('nice', 'to'), ('to', 'meet'), ('meet', 'you'), ('you', '!')]\n",
      "3-gramas de la oración:  Sara said: Hello! nice to meet you!\n",
      "\t [('Sara', 'said', ':'), ('said', ':', 'Hello'), (':', 'Hello', '!'), ('Hello', '!', 'nice'), ('!', 'nice', 'to'), ('nice', 'to', 'meet'), ('to', 'meet', 'you'), ('meet', 'you', '!')]\n",
      "4-gramas de la oración:  Sara said: Hello! nice to meet you!\n",
      "\t [('Sara', 'said', ':', 'Hello'), ('said', ':', 'Hello', '!'), (':', 'Hello', '!', 'nice'), ('Hello', '!', 'nice', 'to'), ('!', 'nice', 'to', 'meet'), ('nice', 'to', 'meet', 'you'), ('to', 'meet', 'you', '!')]\n"
     ]
    }
   ],
   "source": [
    "text_example = 'Sara said: Hello! nice to meet you!'\n",
    "for n in range(2,5):\n",
    "    print(str(n)+'-gramas de la oración: ', text_example)\n",
    "    print('\\t', ngrams(text_example,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f18e57",
   "metadata": {},
   "source": [
    "Creamos la clase ModelNgram, que puede generalizarse fácilmente y que instanciaremos con N=4 para definir el modelo propuesto del apartado 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fb5eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_ngram import ModelNgram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b80dd0",
   "metadata": {},
   "source": [
    "Intanciamos el modelo y lo entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da6e256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4gram = ModelNgram(N=4)\n",
    "model4gram.entrena(train_file_path=TRAIN_RAW_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cb0657",
   "metadata": {},
   "source": [
    "Consultamos el diccionario de conteo para comprobar la distribución de signos dada la terna ('by','the','way')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f57fbf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocurrencias con el signo  <mayus>  para la terna  ('by', 'the', 'way') : 0\n",
      "Ocurrencias con el signo  <minus>  para la terna  ('by', 'the', 'way') : 25\n",
      "Ocurrencias con el signo  .  para la terna  ('by', 'the', 'way') : 36\n",
      "Ocurrencias con el signo  ,  para la terna  ('by', 'the', 'way') : 200\n",
      "Ocurrencias con el signo  ;  para la terna  ('by', 'the', 'way') : 1\n",
      "Ocurrencias con el signo  :  para la terna  ('by', 'the', 'way') : 0\n",
      "Ocurrencias con el signo  ?  para la terna  ('by', 'the', 'way') : 1\n",
      "Ocurrencias con el signo  !  para la terna  ('by', 'the', 'way') : 0\n"
     ]
    }
   ],
   "source": [
    "terna = ('by','the','way')\n",
    "for i in model4gram.counts_dict:\n",
    "    print('Ocurrencias con el signo ',i,' para la terna ',terna, ':',model4gram.counts_dict[i].get(terna,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c21126",
   "metadata": {},
   "source": [
    "Se observa que la mayor ocurrencia se da para la coma ',' por lo que la función predice() del modelo debe devolver dicho caracter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cde1fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La operación más probable dada la terna  ('by', 'the', 'way')  es  ,\n"
     ]
    }
   ],
   "source": [
    "print('La operación más probable dada la terna ',terna, ' es ',model4gram.predice(terna))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d38999",
   "metadata": {},
   "source": [
    "Igual que definimos el modelo de forma genérica para Ngramas, vamos a definir la función genérica addPunctuationNgram donde la función requerida por el apartado addPunctuation4gram es addPunctuationNgram usando un modelo basado en 4 gramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53f7eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from punctuator_ngram import addPunctuationNgram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91219f40",
   "metadata": {},
   "source": [
    "Podemos definir ahora la función de puntuación addPunctuation4gram simplemente como la ejecución de addPunctuationNgram\n",
    "verificando que el modelo usado usa 4gramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2490e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPunctuation4gram(model,example,add_basic_punct = False):\n",
    "    N = model.N\n",
    "    assert N == 4, 'The model is based in {} -grams and it should be 4-grams.'.format(str(N))\n",
    "    return addPunctuationNgram(model,example,add_basic_punct = add_basic_punct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1944aec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase sin puntuar:\n",
      " \t and we also are eating meat that comes from some of these same places\n",
      "Puntuación de la frase con modelo 4 gramas:\n",
      " \t and we also are eating meat, that comes from some of these same places\n",
      "Puntuación de la frase con modelo 4 gramas + addPunctuationBasic:\n",
      " \t And we also are eating meat, that comes from some of these same places.\n"
     ]
    }
   ],
   "source": [
    "text_example = \"and we also are eating meat that comes from some of these same places\"\n",
    "print('Frase sin puntuar:\\n \\t',text_example)\n",
    "print('Puntuación de la frase con modelo 4 gramas:\\n \\t',addPunctuation4gram(model4gram,text_example,add_basic_punct=False))\n",
    "print('Puntuación de la frase con modelo 4 gramas + addPunctuationBasic:\\n \\t',addPunctuation4gram(model4gram,text_example,add_basic_punct=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8975744",
   "metadata": {},
   "source": [
    "Exploremos algunos ejemplos usando puntuación básica o no en el modelo de 4gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "957ba0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODELO 4GRAMS\n",
      "======================================================================\n",
      "TEST LINE: \n",
      "  it can be a very complicated thing the ocean\n",
      "MODEL PUNCTUATED LINE: \n",
      "  it can be a very complicated thing, the ocean\n",
      "VALIDATION LINE: \n",
      "  It can be a very complicated thing, the ocean. \n",
      "\n",
      "Modificaciones necesarias:  {('S', 0), ('I', 7), ('I', 9)}\n",
      "Modificaciones hechas por el modelo:  {('I', 7)}\n",
      "Diferencias entre modelo y validación:  {('I', 10), ('S', 0)} \n",
      "\n",
      "n_hechas (Núm. de modificaciones hechas por el modelo):  1\n",
      "n_correctas (Núm. de modificaciones correctas: \n",
      " interseccion(hechas,necesarias) - error de sustitucion de signo):  1\n",
      "n_necesarias (Núm. de modificaciones necesarias):  3 \n",
      "\n",
      "precision (n_correctas/n_hechas):  1.0\n",
      "recall (n_correctas/n_necesarias):  0.3333333333333333 \n",
      "\n",
      "======================================================================\n",
      "======================================================================\n",
      "4GRAMS + PUNTUACION BÁSICA\n",
      "======================================================================\n",
      "TEST LINE: \n",
      "  it can be a very complicated thing the ocean\n",
      "MODEL PUNCTUATED LINE: \n",
      "  It can be a very complicated thing, the ocean.\n",
      "VALIDATION LINE: \n",
      "  It can be a very complicated thing, the ocean. \n",
      "\n",
      "Modificaciones necesarias:  {('S', 0), ('I', 7), ('I', 9)}\n",
      "Modificaciones hechas por el modelo:  {('S', 0), ('I', 7), ('I', 9)}\n",
      "Diferencias entre modelo y validación:  set() \n",
      "\n",
      "n_hechas (Núm. de modificaciones hechas por el modelo):  3\n",
      "n_correctas (Núm. de modificaciones correctas: \n",
      " interseccion(hechas,necesarias) - error de sustitucion de signo):  3\n",
      "n_necesarias (Núm. de modificaciones necesarias):  3 \n",
      "\n",
      "precision (n_correctas/n_hechas):  1.0\n",
      "recall (n_correctas/n_necesarias):  1.0 \n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Instancia del corpus. Modificar para ver distintos ejemplos.\n",
    "i = 0\n",
    "\n",
    "l = 70\n",
    "print('='*l)\n",
    "print('MODELO 4GRAMS')\n",
    "print('='*l)\n",
    "evaluate_example_from_corpus(addPunctuation4gram, model = model4gram,test_file_path=TEST_RAW_PATH, check_file_path= CHECK_RAW_PATH, add_punct_basic=False,corpus_line = i)\n",
    "print('='*l)\n",
    "print('='*l)\n",
    "print('4GRAMS + PUNTUACION BÁSICA')\n",
    "print('='*l)\n",
    "evaluate_example_from_corpus(addPunctuation4gram, model = model4gram, test_file_path=TEST_RAW_PATH, check_file_path= CHECK_RAW_PATH,add_punct_basic=True,corpus_line = i)\n",
    "print('='*l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c56a6cb",
   "metadata": {},
   "source": [
    "### APARTADO 5\n",
    "\n",
    "Evaluemos el modelo usando la misma función evaluate() anterior. Vamos a comparar el rendimiento usando también la puntuación básica y sin ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c01512bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO 4GRAMS\n",
      "=============================================\n",
      "MÉTRICAS\n",
      "=============================================\n",
      "precision global:  0.3060887512899897\n",
      "recall global:  0.04665135738777564\n",
      "F1 global:  0.08096303979909374\n",
      "=============================================\n",
      "precision media:  0.14062073775442538\n",
      "recall medio:  0.049548668299233246\n",
      "F1 medio:  0.07327751014820442\n",
      "=============================================\n",
      "rendimiento:  0.0\n",
      "=============================================\n",
      "número de instancias en el corpus:  14382\n",
      "=============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MODELO 4GRAMS')\n",
    "evaluate(addPunctuation4gram,model=model4gram,test_file_path=TEST_RAW_PATH, check_file_path= CHECK_RAW_PATH)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c333949",
   "metadata": {},
   "source": [
    "Podemos ver que este modelo tal cual es muy pobre. Usando la función evaluate_example_from_corpus(), podemos ver que nunca pone la mayúscula inicial como era de esperar y rara vez un punto al final. Además las predicciones parecen bastante pobres y esto se puede deber a la falta de variedad en en las tuplas del corpus de entrenamiento. El corpus debería ser más grande y variado. \n",
    "\n",
    "Veamos la evaluación añadiendo la puntuación básica y lo comparamos con lo obtenido en addPunctuationBasic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4876526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4GRAMS + PUNTUACION BÁSICA\n",
      "=============================================\n",
      "MÉTRICAS\n",
      "=============================================\n",
      "precision global:  0.7800087656823536\n",
      "recall global:  0.4478750511183114\n",
      "F1 global:  0.5690220215019384\n",
      "=============================================\n",
      "precision media:  0.8431887161340575\n",
      "recall medio:  0.5991128246565686\n",
      "F1 medio:  0.700498694835623\n",
      "=============================================\n",
      "rendimiento:  0.2369628702544848\n",
      "=============================================\n",
      "número de instancias en el corpus:  14382\n",
      "=============================================\n",
      "\n",
      "PUNTUACIÓN BÁSICA\n",
      "=============================================\n",
      "MÉTRICAS\n",
      "=============================================\n",
      "precision global:  0.9481749791028141\n",
      "recall global:  0.4281984334203655\n",
      "F1 global:  0.5899664102286271\n",
      "=============================================\n",
      "precision media:  0.9474342928660826\n",
      "recall medio:  0.5873733513179556\n",
      "F1 medio:  0.7251692521379949\n",
      "=============================================\n",
      "rendimiento:  0.263384786538729\n",
      "=============================================\n",
      "número de instancias en el corpus:  14382\n",
      "=============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('4GRAMS + PUNTUACION BÁSICA')\n",
    "evaluate(addPunctuation4gram,model=model4gram,test_file_path=TEST_RAW_PATH, check_file_path= CHECK_RAW_PATH,add_punct_basic=True)\n",
    "print()\n",
    "print('PUNTUACIÓN BÁSICA')\n",
    "evaluate(addPunctuationBasic,test_file_path=TEST_RAW_PATH, check_file_path= CHECK_RAW_PATH,)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ee6ed",
   "metadata": {},
   "source": [
    "Podemos ver que en general la precisión es más baja en el modelo de 4gramas pero el recall ligeramente superior, pero no de forma sustancial. Además los F1 son menores en el modelo de puntuación básica que en el de 4 gramas así como el rendimiento.\n",
    "\n",
    "En general podemos concluir que el modelo de puntuación básica es mejor que el basado en 4gramas cuando se añade la puntuación línea a línea por sorprendente que parezca.\n",
    "\n",
    "Probemos ahora a añadir la puntuación al corpus completo y evaluarlo.\n",
    "\n",
    "NOTA: La siguiente celda esta comentada para evitar ejecutarla sin querer ya que tarda mucho en ejecutarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bba1c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('MODELO 4GRAMS')\n",
    "#evaluate(addPunctuation4gram,model=model4gram,all_file=True)\n",
    "#print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02447dfb",
   "metadata": {},
   "source": [
    "Ya que hemos implementado un modelo genérico, vamos a comparar con modelos basados en 3gramas y 5gramas para ver si existe mejoría o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1df5a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3gram = ModelNgram(N=3)\n",
    "model5gram = ModelNgram(N=5)\n",
    "model3gram.entrena(train_file_path=TRAIN_RAW_PATH)\n",
    "model5gram.entrena(train_file_path=TRAIN_RAW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c0b5296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3GRAMAS\n",
      "=============================================\n",
      "MÉTRICAS\n",
      "=============================================\n",
      "precision global:  0.7267446209080256\n",
      "recall global:  0.45847620245997045\n",
      "F1 global:  0.5622498481005332\n",
      "=============================================\n",
      "precision media:  0.8039312953739148\n",
      "recall medio:  0.6054353508863484\n",
      "F1 medio:  0.6907051861838088\n",
      "=============================================\n",
      "rendimiento:  0.2259769155889306\n",
      "=============================================\n",
      "número de instancias en el corpus:  14382\n",
      "=============================================\n",
      "\n",
      "5GRAMAS\n",
      "=============================================\n",
      "MÉTRICAS\n",
      "=============================================\n",
      "precision global:  0.8714429298322759\n",
      "recall global:  0.4363930919500456\n",
      "F1 global:  0.5815586484447053\n",
      "=============================================\n",
      "precision media:  0.9020709308151896\n",
      "recall medio:  0.5925814372753306\n",
      "F1 medio:  0.7152840354304869\n",
      "=============================================\n",
      "rendimiento:  0.2533027395355305\n",
      "=============================================\n",
      "número de instancias en el corpus:  14382\n",
      "=============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('3GRAMAS')\n",
    "evaluate(addPunctuationNgram, model = model3gram,test_file_path=TEST_RAW_PATH, check_file_path= CHECK_RAW_PATH, add_punct_basic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('5GRAMAS')\n",
    "evaluate(addPunctuationNgram, model = model5gram, test_file_path=TEST_RAW_PATH, check_file_path= CHECK_RAW_PATH,add_punct_basic=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a06a197",
   "metadata": {},
   "source": [
    "Observamos que en cuanto a precision, el modelo basado en 3gramas es ligeramente inferior al de 4gramas y este a su vez inferior al de 5 gramas, todos por debajo de la precisión del puntuador básico. En cuanto a recall el orden es inverso: el modelo basado en 3 gramas presenta mayor recall que el de 4 y este a su vez que el de 5.\n",
    "En cuanto al F1, los mayores valores los encontramos para el modelo de 5gramas y de puntuación básica. Es obvio que cuanto mayor sea N, menos probable es la probabilidad de que se de una N-tupla concreta por lo que el modelo basado en N-gramas con N grande coincidirá eventualmente con el de puntuación básica si se considera el parámetro add_punct_basic.\n",
    "\n",
    "Para acabar este apartado podemos explorar algunas predicciones de los modelos de 3 y 5 gramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "4a10a707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODELO 3GRAMS\n",
      "======================================================================\n",
      "TEST LINE: \n",
      "  it can be a very complicated thing the ocean\n",
      "MODEL PUNCTUATED LINE: \n",
      "  It can be a very complicated thing. The ocean.\n",
      "VALIDATION LINE: \n",
      "  It can be a very complicated thing, the ocean. \n",
      "\n",
      "Modificaciones necesarias:  {('S', 0), ('I', 9), ('I', 7)}\n",
      "Modificaciones hechas por el modelo:  {('S', 0), ('I', 9), ('S', 7), ('I', 7)}\n",
      "Diferencias entre modelo y validación:  {('S', 7), ('S', 8)} \n",
      "\n",
      "n_hechas (Núm. de modificaciones hechas por el modelo):  4\n",
      "n_correctas (Núm. de modificaciones correctas: \n",
      " interseccion(hechas,necesarias) - error de sustitucion de signo):  2\n",
      "n_necesarias (Núm. de modificaciones necesarias):  3 \n",
      "\n",
      "precision (n_correctas/n_hechas):  0.5\n",
      "recall (n_correctas/n_necesarias):  0.6666666666666666 \n",
      "\n",
      "======================================================================\n",
      "MODELO 5GRAMS\n",
      "======================================================================\n",
      "TEST LINE: \n",
      "  it can be a very complicated thing the ocean\n",
      "MODEL PUNCTUATED LINE: \n",
      "  It can be a very complicated thing, the ocean.\n",
      "VALIDATION LINE: \n",
      "  It can be a very complicated thing, the ocean. \n",
      "\n",
      "Modificaciones necesarias:  {('S', 0), ('I', 9), ('I', 7)}\n",
      "Modificaciones hechas por el modelo:  {('S', 0), ('I', 9), ('I', 7)}\n",
      "Diferencias entre modelo y validación:  set() \n",
      "\n",
      "n_hechas (Núm. de modificaciones hechas por el modelo):  3\n",
      "n_correctas (Núm. de modificaciones correctas: \n",
      " interseccion(hechas,necesarias) - error de sustitucion de signo):  3\n",
      "n_necesarias (Núm. de modificaciones necesarias):  3 \n",
      "\n",
      "precision (n_correctas/n_hechas):  1.0\n",
      "recall (n_correctas/n_necesarias):  1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instancia del corpus. Modificar para ver distintos ejemplos.\n",
    "i= 0\n",
    "\n",
    "l = 70 \n",
    "print('='*l)\n",
    "print('MODELO 3GRAMS')\n",
    "print('='*l)\n",
    "evaluate_example_from_corpus(addPunctuationNgram, model = model3gram,test_file_path=TEST_RAW_PATH, check_file_path= CHECK_RAW_PATH, add_punct_basic=True,corpus_line = i)\n",
    "print('='*l)\n",
    "print('MODELO 5GRAMS')\n",
    "print('='*l)\n",
    "evaluate_example_from_corpus(addPunctuationNgram, model = model5gram,test_file_path=TEST_RAW_PATH, check_file_path= CHECK_RAW_PATH, add_punct_basic=True,corpus_line = i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3633a0",
   "metadata": {},
   "source": [
    "### APARTADO 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67cea767",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PREP_PATH  = prepare_file(TEST_RAW_PATH,'test.prepared.txt')\n",
    "CHECK_PREP_PATH = prepare_file(CHECK_RAW_PATH,'check.prepared.txt')\n",
    "TRAIN_PREP_PATH = prepare_file(TRAIN_RAW_PATH,'train.prepared.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567edf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessor import train_dev_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6766b5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6844/1844126050.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTRAIN_TRAIN_PREP_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAIN_DEV_PREP_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAIN_TEST_PREP_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dev_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_PREP_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\julian\\Desktop\\TRABAJO_PLN\\preprocessor.py\u001b[0m in \u001b[0;36mtrain_dev_test_split\u001b[1;34m(data_path, train_split, dev_split)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0mprop_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdev_split\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mtrain_split\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_split\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[0mdev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprop_split\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\julian\\Desktop\\TRABAJO_PLN\\preprocessor.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(X, split, shuffle)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[0mtrain_indexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msize_1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;31m# Definimos los conjutos de entrenamiento y test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mX_0\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_indexes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[0mX_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_indexes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "TRAIN_TRAIN_PREP_PATH, TRAIN_DEV_PREP_PATH, TRAIN_TEST_PREP_PATH = train_dev_test_split(TRAIN_PREP_PATH, train_split = 0.7, dev_split = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .punctuator2tf2/data.py settings.DATA_PREPARED_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .punctuator2tf2/main.py punctuator 10 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./punctutator2tf2/punctuator.py ./Model_punctuator_h256_lr0.02.pcl TEST_RAW_PATH .predicted/data.model_output.test.txt "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "caf8521805df2f681626d7ffc655f9a444f7479c982c19b2313015333928fe69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
