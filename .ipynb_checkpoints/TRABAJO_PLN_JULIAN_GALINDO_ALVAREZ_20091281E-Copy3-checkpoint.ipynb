{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75e6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos re para expresiones regulares\n",
    "import re \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "028bb48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signos de puntuación (sdp)\n",
    "punct_marks = ['.',',',';',':','?','!']\n",
    "# Signos que afectan a las mayúscualas del entorno\n",
    "mayus_marks = ['.','?','!']\n",
    "\n",
    "# Ubicación de los archivos de corpus:\n",
    "DATASET_PATH = 'PLN-MULCIA-Junio-2022-Dataset'\n",
    "TEST_PATH = os.path.join(DATASET_PATH,'PunctuationTask.test.en')\n",
    "CHECK_PATH = os.path.join(DATASET_PATH,'PunctuationTask.check.en')\n",
    "TRAIN_PATH = os.path.join(DATASET_PATH,'PunctuationTask.train.en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec49d2c",
   "metadata": {},
   "source": [
    "### APARTADO 1\n",
    "\n",
    "Vamos a implementar un sistema que reciba una expresión como entrada (será una expresión formada solo por minúsculas y sin los signos de puntuación mencionados) y la salida será la misma expresión pero con los cambios correspondientes a la introducción de mayúsculas y signos de puntuación indicados.\n",
    "\n",
    "Como primera versión de esta función addPunctuationBasic se implementará un modelo que\n",
    "simplemente cambia la primera letra por mayúscula y añade al final del string de entrada un punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a142e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que pone el primer caracter de un string en mayúscula o minúscula según el parámetro booleano 'uppercase'\n",
    "def change_initial(string,uppercase):\n",
    "    if not string:\n",
    "        return\n",
    "    init = string[0]\n",
    "    new_initial = init.upper() if uppercase else init.lower()\n",
    "    temp = list(string)\n",
    "    temp[0] = new_initial\n",
    "    return ''.join(temp)\n",
    "\n",
    "# Función del apartado 1. Pone en maúscula la primera letra y añade un punto '.' al final si no lo tiene\n",
    "def addPunctuationBasic(string):\n",
    "    initial_upper = change_initial(string,uppercase=True)\n",
    "    last_char = initial_upper[-1]\n",
    "    add_dot = '.' if last_char not in punct_marks else ''\n",
    "    return initial_upper + add_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763b8a98",
   "metadata": {},
   "source": [
    "Vemos que la función anterior realiza la operación correctamente con el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25868085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Esta es una frase de prueba.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addPunctuationBasic('esta es una frase de prueba')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb097359",
   "metadata": {},
   "source": [
    "### APARTADO 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da97fae",
   "metadata": {},
   "source": [
    "Antes de definir la función verifyPuntuation vamos a definir dos funciones auxiliares que nos servirán.\n",
    "* padding(list1,list2): Devuelve las los listas de entrada de forma que ambas tengan la misma longitud, añadiendo el elemento string vacío ('') a la lista de menor longitud.\n",
    "\n",
    "* tokenizer(text): tokeniza el texto de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3781fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dadas dos listas, añade '' a la menor hasta que ambas tengan el mismo tamaño.\n",
    "def padding(list1, list2):\n",
    "    len1, len2 = len(list1), len(list2)\n",
    "    max_len = max(len1, len2)\n",
    "    list1 = [*list1, *([''] * (max_len - len1))]\n",
    "    list2 = [*list2, *([''] * (max_len - len2))]\n",
    "    return list1, list2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8162c1",
   "metadata": {},
   "source": [
    "Veamos su funcionamiento con el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2ce2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista 1 con padding:  ['s', 'a', '', ''] \t Lista 2 con padding:  ['1', '2', '3', '4']\n",
      "Las longitudes son iguales:  True\n"
     ]
    }
   ],
   "source": [
    "list1, list2 = ['s','a'], ['1','2','3','4']\n",
    "l1, l2 = padding(list1,list2)\n",
    "print('Lista 1 con padding: ',l1,'\\t Lista 2 con padding: ', l2)\n",
    "print('Las longitudes son iguales: ', len(l1) == len(l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f031a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que tokeniza un texto\n",
    "def tokenizer(text):\n",
    "    # Generamos la expresión regular que añade espacios a los signos para poder separarlos con el método split()\n",
    "    marks = ''.join([p + '|' for p in punct_marks])[:-1]\n",
    "    regex1, regex2 = r' ?(['+ marks +']+) ?', r' \\1 '\n",
    "    text = re.sub(regex1, regex2, text)\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf854a0",
   "metadata": {},
   "source": [
    "Veamos cómo funciona con el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12cf027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sara', 'said', ':', 'Hello', ',', \"what's\", 'your', 'name', '?']\n"
     ]
    }
   ],
   "source": [
    "text_example= \"Sara said: Hello, what's your name?\"\n",
    "print(tokenizer(text_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80814bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función veryfyPunctuation del apartado 2.\n",
    "def verifyPunctuation(check, test):\n",
    "    # Tokenizamos los textos\n",
    "    check = tokenizer(check)\n",
    "    test = tokenizer(test)\n",
    "    # Hacemos padding\n",
    "    check, test = padding(check, test)\n",
    "    l_check = len(check)\n",
    "    modifications = []   \n",
    "    \n",
    "    for i in range(l_check):\n",
    "        # Deletions:\n",
    "        # Si test[i] no es un sdp pero check[i] si y las palabras anteriores coinciden salvo mayúsculas\n",
    "        # añadimos la modificación ('D', i) e insertamos el correspondiente sdp faltante en test.\n",
    "        if check[i] in punct_marks:\n",
    "            if test[i] not in punct_marks and test[i-1].upper() == check[i - 1].upper():\n",
    "                modifications.append(('D',i))\n",
    "                test.insert(i,check[i])\n",
    "                \n",
    "        # Reestablecemos el padding para mantener misma longitud\n",
    "        check, test = padding(check, test)\n",
    "\n",
    "        # Insertions:\n",
    "        # Si test[i] es un sdp pero check[i] no y las palabras anteriores coinciden salvo mayúsculas\n",
    "        # añadimos la modificación ('I', i) y eliminamos el correspondiente sdp en test.\n",
    "        if check[i] not in punct_marks:\n",
    "            if test[i] in punct_marks and test[i-1].upper() == check[i - 1].upper():\n",
    "                modifications.append(('I',i))\n",
    "                test.pop(i)\n",
    "                \n",
    "    # Reestablecemos el padding para mantener misma longitud\n",
    "    check, test = padding(check, test)\n",
    "    \n",
    "    # Substitutions:\n",
    "    # Tras haber transformado test para añadir los as sustituciones son aquellos elementos que no coinciden\n",
    "    for i in range(l_check):\n",
    "        if check[i] != test[i] and check[i] != '' and test[i] != '':\n",
    "            modifications.append(('S',i))\n",
    "    return set(modifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5fbedc",
   "metadata": {},
   "source": [
    "Utilicemos el ejemplo del documento para ver si funciona correctamente la función. Además verificamos que intercambiar check y test devuelve el mismo número de elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "6f21d9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check vs test:  {('I', 4), ('S', 2), ('D', 1)}\n",
      "test vs check:  {('S', 1), ('I', 1), ('D', 3)}\n"
     ]
    }
   ],
   "source": [
    "check_example = \"Hello. What's your name?\"\n",
    "test_example = \"Hello what's your, name?\"\n",
    "print('check vs test: ', verifyPunctuation(check_example,test_example))\n",
    "print('test vs check: ', verifyPunctuation(test_example,check_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c3077",
   "metadata": {},
   "source": [
    "### APARTADO 3\n",
    "\n",
    "Implementaremos una herramienta que permita recorrer todo el corpus de test y verificación. Es decir, irá recorriendo una a una las líneas de cada fichero (que están alineadas), aplicaría sobre la frase de test el algoritmo básico de puntuación (apartado 1: addPunctuationBasic() ) y a continuación comprobaría si el resultado es o no correcto usando la función verifyPunctuation() del apartado 2.\n",
    "\n",
    "En primer lugar vamos a definir una función evaluate_example que calcula las métricas precision y recall dado una instancia (check,test). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "6771be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_example(punctuationFunction, check, test,model = None, add_punct_basic = False, print_info = True):\n",
    "    if model is not None: punctuated = punctuationFunction(model,test,add_punct_basic)\n",
    "    else: punctuated = punctuationFunction(test)\n",
    "    # Diferencia entre el check y el test original (cambios necesarios)\n",
    "    vct = verifyPunctuation(test,check)\n",
    "    # Diferencia entre el test original y el modificado (modificaciones hechas por la función)\n",
    "    vtmt = verifyPunctuation(test,punctuated)\n",
    "    # Diferencia entre el check y el modificado (modificaciones hechas por la función)\n",
    "    vcmt = verifyPunctuation(punctuated,check)\n",
    "    es_correcto = 1 if len(vcmt) == 0 else 0\n",
    "    # número de cambios hechos por la función            \n",
    "    hechos_ = len(vtmt)\n",
    "    # número de cambios necesarios\n",
    "    necesarios_ = len(vct)\n",
    "    # número de cambios correctos hechos (intersección entre cambios hechos y necesarios)\n",
    "    correctos_ = len(vtmt & vct) \n",
    "    \n",
    "    # CORRECCIÓN DE ERROR DE SUSTITUCIÓN DE SIGNO\n",
    "    # Esta definición de correctos_ es incompleta bajo el uso de verifyPunctuation ya que por ejemplo si\n",
    "    # el modelo añade al final (token 23 por ejemplo) un '.' y debía añadir '?', en ambos casos recibiremos\n",
    "    # ('I',23) y sin embargo es incorrecto. En resumen, verifyPunctuation no nos devuelve información sobre el \n",
    "    # token en si. Corregimos esto con un factor de error.\n",
    "    error_ = 0\n",
    "    l_t = len(tokenizer(test))\n",
    "    l_c = len(tokenizer(check))\n",
    "    cambios = list(vtmt)\n",
    "    diferencias = list(vcmt)\n",
    "    # Para cada token que aparece en la verificación de la predicción con el test (cambios), comprobamos si \n",
    "    # en la verificación de la predicción con el check (diferencias) aparecen operaciones distintas, esto es,\n",
    "    # se ha insertado un signo incorrecto (I) ya que en la verificación aparece una sustitución de ese signo (S)\n",
    "    for j in range(len(cambios)):\n",
    "        token = cambios[j][1]\n",
    "        operacion = cambios[j][0]\n",
    "        for k in range(len(diferencias)):\n",
    "            error_ += 1 if token == diferencias[k][1] and token<l_t and diferencias[k][1]<l_c and operacion == 'I' and diferencias[k][0] == 'S' else 0\n",
    "    # El token final lo tratamos por separado\n",
    "    error_ += 1 if punctuated[-1] in punct_marks and check[-1] in punct_marks and punctuated[-1] != check[-1] else 0\n",
    "    # Corregimos correctos_ en base al error\n",
    "    correctos_ -= error_\n",
    "    # métricas medias\n",
    "    precision = (correctos_ / hechos_) if hechos_ != 0 else 0\n",
    "    recall = (correctos_ / necesarios_) if necesarios_ != 0 else 0\n",
    "    \n",
    "    # Si print_info decuelve información sobre el proceso\n",
    "    if print_info:\n",
    "        print('TEST LINE: \\n ',test)\n",
    "        print('MODEL PUNCTUATED LINE: \\n ',punctuated)\n",
    "        print('VALIDATION LINE: \\n ',check,'\\n')\n",
    "        print('Modificaciones necesarias: ', vct)\n",
    "        print('Modificaciones hechas por el modelo: ',vtmt)\n",
    "        print('Diferencias entre modelo y validación: ',vcmt, '\\n')\n",
    "        print('n_hechas (Núm. de modificaciones hechas por el modelo): ',hechos_)\n",
    "        print('n_correctas (Núm. de modificaciones correctas: \\n interseccion(hechas,necesarias) - error de sustitucion de signo): ',correctos_)\n",
    "        print('n_necesarias (Núm. de modificaciones necesarias): ',necesarios_, '\\n')\n",
    "        print('precision (n_correctas/n_hechas): ',precision)\n",
    "        print('recall (n_correctas/n_necesarias): ',recall,'\\n')\n",
    "    \n",
    "    return es_correcto, precision, recall, hechos_, correctos_, necesarios_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638bf505",
   "metadata": {},
   "source": [
    "Comprobamos el funcionamiento de la función con el siguiente ejemplo.\n",
    "\n",
    "* check = \"Hello. What's your name?\"\n",
    "* test = \"hello what's your name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "2a7de147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LINE: \n",
      "  hello what's your name\n",
      "MODEL PUNCTUATED LINE: \n",
      "  Hello what's your name.\n",
      "VALIDATION LINE: \n",
      "  Hello. What's your name? \n",
      "\n",
      "Modificaciones necesarias:  {('S', 0), ('S', 1), ('I', 4), ('I', 1)}\n",
      "Modificaciones hechas por el modelo:  {('S', 0), ('I', 4)}\n",
      "Diferencias entre modelo y validación:  {('S', 1), ('S', 4), ('I', 1)} \n",
      "\n",
      "n_hechas (Núm. de modificaciones hechas por el modelo):  2\n",
      "n_correctas (Núm. de modificaciones correctas: \n",
      " interseccion(hechas,necesarias) - error de sustitucion de signo):  1\n",
      "n_necesarias (Núm. de modificaciones necesarias):  4 \n",
      "\n",
      "precision (n_correctas/n_hechas):  0.5\n",
      "recall (n_correctas/n_necesarias):  0.25 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.5, 0.25, 2, 1, 4)"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_example = \"Hello. What's your name?\"\n",
    "test_example = \"hello what's your name\"\n",
    "evaluate_example(addPunctuationBasic,check_example,test_example,add_punct_basic=False,print_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c460dae",
   "metadata": {},
   "source": [
    "Notemos que la oración puntuada es \"Hello what's your name.\", por lo que la función de validación va a considerar como correcto el haber insertado en el token 4, lo que se observa como ('I', 4) tanto en las modificaciones necesarias como las hechas por el modelo. Al no tener información sobre el caracter, esto podría dar lugar a un falso positivo, que es corregido correctamente con el error de sustitución de signo visto en la función.\n",
    "\n",
    "Definamos ahora la función evaluate(...) que raliza el proceso anterior para distintos corpus y calcula métricas gobales, es decir, la que pide el propio apartado 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "b2c034b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función calcula las métricas de una función de puntuación. los atributos son:\n",
    "#   punctuationFunction: función a evaluar.\n",
    "#   check_file_path y test_file_path: rutas a los archivos de check y test.\n",
    "#   model: modelo de predicción usado (4gramas más adelante)\n",
    "#   add_punct_basic se usa para la función addPunctuation4gram que definiremos más adelante\n",
    "def evaluate(punctuationFunction, check_file_path = CHECK_PATH, test_file_path = TEST_PATH, model = None, add_punct_basic = False):\n",
    "    # número de instancias correctamente puntuadas\n",
    "    num_correctos = 0\n",
    "    # número de cambios globales hechos por la función  \n",
    "    hechos = 0\n",
    "    # número de modificaciones correctas globales\n",
    "    correctos = 0\n",
    "    # número de modificaciones necesarias globales\n",
    "    necesarios = 0\n",
    "    \n",
    "    # precisión y recall por instancia para calcular las medias\n",
    "    precision_, recall_ = [], []\n",
    "    \n",
    "    with open(test_file_path, 'r', encoding='utf-8-sig') as test_file, open(check_file_path, 'r', encoding='utf-8-sig') as check_file:\n",
    "        test_lines = test_file.readlines()\n",
    "        check_lines = check_file.readlines()\n",
    "        \n",
    "        # número de instancias\n",
    "        N = len(test_lines)\n",
    "        #testeo = True\n",
    "        for i in range(N):\n",
    "            check = check_lines[i].rstrip(' \\n')\n",
    "            test = test_lines[i].rstrip(' \\n')\n",
    "            es_correcto, prec, rec, hechos_, correctos_, necesarios_ = evaluate_example(punctuationFunction,check,test,model=model,add_punct_basic = add_punct_basic,print_info=False)\n",
    "            num_correctos += es_correcto\n",
    "            # métricas medias\n",
    "            precision_.append(prec)\n",
    "            recall_.append(rec)\n",
    "            hechos += hechos_\n",
    "            correctos += correctos_\n",
    "            necesarios += necesarios_\n",
    "        test_file.close()\n",
    "        check_file.close()\n",
    "        \n",
    "    # Métricas globales\n",
    "    precision = correctos / hechos\n",
    "    recall = correctos / necesarios\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    # Métricas medias\n",
    "    precision_media = sum(precision_)/len(precision_)\n",
    "    recall_media = sum(recall_)/len(recall_)\n",
    "    F1_media = 2 * (precision_media * recall_media) / (precision_media + recall_media)\n",
    "    rendimiento = num_correctos/N\n",
    "    w = 45\n",
    "    print('='*w)\n",
    "    print('MÉTRICAS')\n",
    "    print('='*w)\n",
    "    print ('precision global: ', precision)\n",
    "    print ('recall global: ', recall)\n",
    "    print ('F1 global: ', F1)\n",
    "    print('='*w)\n",
    "    print ('precision media: ', precision_media)\n",
    "    print ('recall medio: ', recall_media)\n",
    "    print ('F1 medio: ', F1_media)\n",
    "    print('='*w)\n",
    "    print ('rendimiento: ', rendimiento)\n",
    "    print('='*w)\n",
    "    print('número de instancias en el corpus: ',N)\n",
    "    print('='*w)\n",
    "    \n",
    "    result_dict = {'precision_global':precision, 'recall_global':recall, 'F1_global':F1,'precision_mean':precision_media, 'recall_mean':recall_media, 'F1_mean':F1_media, 'score':rendimiento }\n",
    "    return result_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42740c1b",
   "metadata": {},
   "source": [
    "Evaluamos la función addPunctuationBasic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "e40008f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "MÉTRICAS\n",
      "=============================================\n",
      "precision global:  0.9481749791028141\n",
      "recall global:  0.4281984334203655\n",
      "F1 global:  0.5899664102286271\n",
      "=============================================\n",
      "precision media:  0.9474342928660826\n",
      "recall medio:  0.5873733513179556\n",
      "F1 medio:  0.7251692521379949\n",
      "=============================================\n",
      "rendimiento:  0.263384786538729\n",
      "=============================================\n",
      "número de instancias en el corpus:  14382\n",
      "=============================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision_global': 0.9481749791028141,\n",
       " 'recall_global': 0.4281984334203655,\n",
       " 'F1_global': 0.5899664102286271,\n",
       " 'precision_mean': 0.9474342928660826,\n",
       " 'recall_mean': 0.5873733513179556,\n",
       " 'F1_mean': 0.7251692521379949,\n",
       " 'score': 0.263384786538729}"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(addPunctuationBasic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cd307",
   "metadata": {},
   "source": [
    "Vemos que la precisión es alta, lo que indica que lo que tiene que hacer el modelo (poner la primera letra en mayúscula y un punto al final), lo hace bien. Sin embargo, el recall es relativamente bajo ya que esos cambios no son suficientes para puntuar correctamente las oraciones, cosa que también se deduce del bajo rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f6c1ac",
   "metadata": {},
   "source": [
    "Aunque no se pide, definimos la función evaluate_example_from_corpus que permite ver la información resultante de evaluate_example para un elemento en concreto del corpus dado el número de línea corpus_line. De esta forma podemos explorar y verificar el correcto funcionamiento de las funciones definidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "edded325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_example_from_corpus(punctuationFunction, corpus_line = 0, check_file_path = CHECK_PATH, test_file_path = TEST_PATH,model = None,add_punct_basic = False):\n",
    "   \n",
    "    with open(test_file_path, 'r', encoding='utf-8-sig') as test_file, open(check_file_path, 'r', encoding='utf-8-sig') as check_file:\n",
    "        check = check_file.readlines()[corpus_line].rstrip(' \\n')\n",
    "        test = test_file.readlines()[corpus_line].rstrip(' \\n')\n",
    "        evaluate_example(punctuationFunction,check,test,model = model,add_punct_basic = add_punct_basic,print_info=True)\n",
    "    test_file.close()\n",
    "    check_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "28b6cd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LINE: \n",
      "  and what do i mean by that\n",
      "MODEL PUNCTUATED LINE: \n",
      "  And what do i mean by that.\n",
      "VALIDATION LINE: \n",
      "  And what do I mean by that? \n",
      "\n",
      "Modificaciones necesarias:  {('S', 0), ('S', 3), ('I', 7)}\n",
      "Modificaciones hechas por el modelo:  {('S', 0), ('I', 7)}\n",
      "Diferencias entre modelo y validación:  {('S', 7), ('S', 3)} \n",
      "\n",
      "n_hechas (Núm. de modificaciones hechas por el modelo):  2\n",
      "n_correctas (Núm. de modificaciones correctas: \n",
      " interseccion(hechas,necesarias) - error de sustitucion de signo):  1\n",
      "n_necesarias (Núm. de modificaciones necesarias):  3 \n",
      "\n",
      "precision (n_correctas/n_hechas):  0.5\n",
      "recall (n_correctas/n_necesarias):  0.3333333333333333 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_example_from_corpus(addPunctuationBasic,corpus_line=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1614e4d2",
   "metadata": {},
   "source": [
    "### APARTADO 4\n",
    "\n",
    "Utilizando el corpus de entrenamiento contenido en PunctuationTask.train.en construimos un modelo de lenguaje inspirado en la idea de 4-gramas.\n",
    "\n",
    "Definimos una función auxiliar ngrams(text,N) que dado el string text devuelve la lista de N-gramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "7f67d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(text,N):\n",
    "    text = tokenizer(text)\n",
    "    return [tuple(text[i:i+N]) for i in range(len(text)-N+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a8720",
   "metadata": {},
   "source": [
    "Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "2ca0d27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gramas de la oración:  Sara said: Hello! nice to meet you!\n",
      "\t [('Sara', 'said'), ('said', ':'), (':', 'Hello'), ('Hello', '!'), ('!', 'nice'), ('nice', 'to'), ('to', 'meet'), ('meet', 'you'), ('you', '!')]\n",
      "3-gramas de la oración:  Sara said: Hello! nice to meet you!\n",
      "\t [('Sara', 'said', ':'), ('said', ':', 'Hello'), (':', 'Hello', '!'), ('Hello', '!', 'nice'), ('!', 'nice', 'to'), ('nice', 'to', 'meet'), ('to', 'meet', 'you'), ('meet', 'you', '!')]\n",
      "4-gramas de la oración:  Sara said: Hello! nice to meet you!\n",
      "\t [('Sara', 'said', ':', 'Hello'), ('said', ':', 'Hello', '!'), (':', 'Hello', '!', 'nice'), ('Hello', '!', 'nice', 'to'), ('!', 'nice', 'to', 'meet'), ('nice', 'to', 'meet', 'you'), ('to', 'meet', 'you', '!')]\n"
     ]
    }
   ],
   "source": [
    "text_example = 'Sara said: Hello! nice to meet you!'\n",
    "for n in range(2,5):\n",
    "    print(str(n)+'-gramas de la oración: ', text_example)\n",
    "    print('\\t', ngrams(text_example,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f18e57",
   "metadata": {},
   "source": [
    "Creamos la clase modelNgram, que puede generalizarse fácilmente y que instanciaremos con N=4 para definir el modelo propuesto del apartado 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "7fb5eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelNgram():\n",
    "    # Definimos por defecto 4grams\n",
    "    def __init__(self, N = 4):\n",
    "        assert N > 1, 'N must be greater or equal 2' \n",
    "        self.N = N\n",
    "        self.punct_marks = ['.',',',';',':','?','!']\n",
    "        self.mayus_marks = ['.','?','!']\n",
    "        self.minus = '<minus>'\n",
    "        self.mayus = '<mayus>'\n",
    "        # Diccionario con una clave para cada operación y valor un diccionario donde cada clave es una terna posible \n",
    "        # y su valor es el número de veces que aparece dicha terna seguida de la operación\n",
    "        self.counts_dict = dict()\n",
    "        # Diccionario donde cada clave es una terna y el valor es la operación predicha entrenada por el modelo\n",
    "        # deducida del argumento del máximo en el diccionario counts_dict.\n",
    "        self.trained_dict = dict()\n",
    "        self.trained = False\n",
    "                \n",
    "    def entrena(self, train_file_path = TRAIN_PATH):\n",
    "        \n",
    "        # Conjunto de tuplas vistas\n",
    "        tuplas = set()\n",
    "        \n",
    "        # Inicializamos los subdiccionarios de cada operación\n",
    "        self.counts_dict[self.mayus]= {}\n",
    "        self.counts_dict[self.minus]={}\n",
    "        for s in model.punct_marks:\n",
    "            self.counts_dict[s] = {}\n",
    "        \n",
    "        # Recorremos el archivo de entrenamiento\n",
    "        with open(train_file_path, 'r', encoding='utf-8') as train:\n",
    "            train_lines = train.readlines()\n",
    "            for line in train_lines:\n",
    "                # Eliminamos el espacio final y retorno de carro del final de las líneas\n",
    "                line = line.rstrip(' \\n')\n",
    "                # Obtenemos los 4gramas de la línea\n",
    "                ngs = ngrams(line,self.N)\n",
    "                for ng in ngs:\n",
    "                    # obtenemos la operación correspondiente a partir del último elemento del 4grama\n",
    "                    last = ng[-1]\n",
    "                    op = last if last in self.punct_marks else self.mayus if last.isupper() else self.minus \n",
    "                    # Construimos la N-1 tupla  \n",
    "                    tupla =  tuple([x.lower() for x in list(ng)[:-1]]) if len(ng) > 2 else ng[0]\n",
    "                    tuplas.add(tupla)\n",
    "                    # Sumamos una ocurrencia a la entrada correspondiente del diccionario\n",
    "                    self.counts_dict[op][tupla]= self.counts_dict[op].get(tupla,0) + 1\n",
    "        train.close()\n",
    "        # Construimos el diccionario trained_model a partir de counts_dict\n",
    "        for tupla in tuplas:\n",
    "            self.trained_dict[tupla] = self.operacion_mas_probable(tupla)\n",
    "        self.trained = True\n",
    "        \n",
    "    # Predice la operación dada una tupla calculando el máximo de ocurrencias consultando counts_dict        \n",
    "    def operacion_mas_probable(self, tupla):  \n",
    "        v = 0\n",
    "        prediction = 'NONE'\n",
    "        for i in self.counts_dict:\n",
    "            value = self.counts_dict[i].get(tupla,0) \n",
    "            if value > v:\n",
    "                prediction = i\n",
    "                v = value\n",
    "        return prediction\n",
    "    \n",
    "    # Predice la operación dada una tupla consultando directamente el diccionario trained_model\n",
    "    def predice(self,tupla):\n",
    "        #Devolvemos excepción si modelo aún no entrenado\n",
    "        self.check_entrenado()\n",
    "        return self.trained_dict.get(tupla,'NONE')\n",
    "    \n",
    "    def check_entrenado(self):\n",
    "         if not self.trained:\n",
    "            raise NotTrainedModel(Exception(\"Model has not been trained yet\"))\n",
    "        \n",
    "class NotTrainedModel(Exception): pass        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b80dd0",
   "metadata": {},
   "source": [
    "Intanciamos el modelo y lo entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "da6e256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4gram = modelNgram(N=4)\n",
    "model4gram.entrena()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cb0657",
   "metadata": {},
   "source": [
    "Consultamos el diccionario de conteo para comprobar la distribución de signos dada la terna ('by','the','way')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "f57fbf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocurrencias con el signo  <mayus>  para la terna  ('by', 'the', 'way') : 0\n",
      "Ocurrencias con el signo  <minus>  para la terna  ('by', 'the', 'way') : 25\n",
      "Ocurrencias con el signo  .  para la terna  ('by', 'the', 'way') : 36\n",
      "Ocurrencias con el signo  ,  para la terna  ('by', 'the', 'way') : 200\n",
      "Ocurrencias con el signo  ;  para la terna  ('by', 'the', 'way') : 1\n",
      "Ocurrencias con el signo  :  para la terna  ('by', 'the', 'way') : 0\n",
      "Ocurrencias con el signo  ?  para la terna  ('by', 'the', 'way') : 1\n",
      "Ocurrencias con el signo  !  para la terna  ('by', 'the', 'way') : 0\n"
     ]
    }
   ],
   "source": [
    "terna = ('by','the','way')\n",
    "for i in model4gram.counts_dict:\n",
    "    print('Ocurrencias con el signo ',i,' para la terna ',terna, ':',model4gram.counts_dict[i].get(terna,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c21126",
   "metadata": {},
   "source": [
    "Se observa que la mayor ocurrencia se da para la coma ',' por lo que la función predice() del modelo debe devolver dicho caracter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "4cde1fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La operación más probable dada la terna  ('by', 'the', 'way')  es  ,\n"
     ]
    }
   ],
   "source": [
    "print('La operación más probable dada la terna ',terna, ' es ',model4gram.predice(terna))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d38999",
   "metadata": {},
   "source": [
    "Igual que definimos el modelo de forma genérica para Ngramas, vamos a definir la función genérica addPunctuationNgram donde la función requerida por el apartado addPunctuation4gram es addPunctuationNgram usando un modelo basado en 4 gramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "53f7eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPunctuationNgram(model,example,add_basic_punct = False):\n",
    "    model.check_entrenado()\n",
    "    # Trabajamos con los tokens\n",
    "    tokens = tokenizer(example)\n",
    "    num_tokens = len(tokens)\n",
    "    # Generamos los (N-1)-gramas del texto\n",
    "    N = model.N -1\n",
    "    grams = ngrams(example,N)\n",
    "    added_tokens = 0\n",
    "    for i in range(len(grams)):\n",
    "        # Calculamos el 4-grama predicho\n",
    "        operation = model.predice(grams[i]) if N > 1 else model.predice(grams[i][0])\n",
    "        target_index = i+N+added_tokens\n",
    "        # Transformamos los tokens del texto\n",
    "        if operation == model.mayus and target_index < num_tokens:\n",
    "            tokens[target_index] = change_initial(tokens[target_index], uppercase = True)\n",
    "        if operation == model.minus and target_index < num_tokens:\n",
    "            tokens[target_index] = change_initial(tokens[target_index], uppercase = False)\n",
    "        if operation in model.punct_marks:\n",
    "            added_tokens += 1\n",
    "            num_tokens += 1\n",
    "            tokens.insert(target_index, operation)\n",
    "            if operation in model.mayus_marks and target_index < num_tokens -1:\n",
    "                tokens[target_index+1] = change_initial(tokens[target_index+1], uppercase = True)\n",
    "\n",
    "    # Añadimos los espacios excepto para los signos de puntuación\n",
    "    result = [' ' + x if x not in model.punct_marks else x for x in tokens]\n",
    "    # Reconstruimos el texto predicho\n",
    "    result = ''.join(result)[1:]\n",
    "    \n",
    "    \n",
    "    # Puesto que el modelo de 4 gramas dificilmente va a poner la primera letra en mayúscula y es probable que\n",
    "    # deje el final de la oración sin puntuar, añadimos la funcionalidad de addPunctuationBasic como\n",
    "    # parámetro de la función.\n",
    "    if add_basic_punct:\n",
    "        dot = '' if result[-1] in model.punct_marks else '.'\n",
    "        result = change_initial(result + dot,uppercase=True)\n",
    "    return result \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91219f40",
   "metadata": {},
   "source": [
    "Podemos definir ahora la función de puntuación addPunctuation4gram simplemente como la ejecución de addPunctuationNgram\n",
    "verificando que el modelo usado usa 4gramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "2490e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPunctuation4gram(model,example,add_basic_punct = False):\n",
    "    N = model.N\n",
    "    assert N == 4, 'The model is based in ' + str(N) +'-grams and it should be 4-grams.'\n",
    "    return addPunctuationNgram(model,example,add_basic_punct = add_basic_punct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "1944aec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase sin puntuar:\n",
      " \t and we also are eating meat that comes from some of these same places\n",
      "Puntuación de la frase con modelo 4 gramas:\n",
      " \t and we also are eating meat, that comes from some of these same places\n",
      "Puntuación de la frase con modelo 4 gramas + addPunctuationBasic:\n",
      " \t And we also are eating meat, that comes from some of these same places.\n"
     ]
    }
   ],
   "source": [
    "text_example = \"and we also are eating meat that comes from some of these same places\"\n",
    "print('Frase sin puntuar:\\n \\t',text_example)\n",
    "print('Puntuación de la frase con modelo 4 gramas:\\n \\t',addPunctuation4gram(model4gram,text_example,add_basic_punct=False))\n",
    "print('Puntuación de la frase con modelo 4 gramas + addPunctuationBasic:\\n \\t',addPunctuation4gram(model4gram,text_example,add_basic_punct=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8975744",
   "metadata": {},
   "source": [
    "Exploremos algunos ejemplos usando puntuación básica o no en el modelo de 4gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "957ba0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODELO 4GRAMS\n",
      "======================================================================\n",
      "TEST LINE: \n",
      "  it can be a very complicated thing the ocean\n",
      "MODEL PUNCTUATED LINE: \n",
      "  it can be a very complicated thing, the ocean\n",
      "VALIDATION LINE: \n",
      "  It can be a very complicated thing, the ocean. \n",
      "\n",
      "Modificaciones necesarias:  {('S', 0), ('I', 9), ('I', 7)}\n",
      "Modificaciones hechas por el modelo:  {('I', 7)}\n",
      "Diferencias entre modelo y validación:  {('S', 0), ('I', 10)} \n",
      "\n",
      "n_hechas (Núm. de modificaciones hechas por el modelo):  1\n",
      "n_correctas (Núm. de modificaciones correctas: \n",
      " interseccion(hechas,necesarias) - error de sustitucion de signo):  1\n",
      "n_necesarias (Núm. de modificaciones necesarias):  3 \n",
      "\n",
      "precision (n_correctas/n_hechas):  1.0\n",
      "recall (n_correctas/n_necesarias):  0.3333333333333333 \n",
      "\n",
      "======================================================================\n",
      "======================================================================\n",
      "4GRAMS + PUNTUACION BÁSICA\n",
      "======================================================================\n",
      "TEST LINE: \n",
      "  it can be a very complicated thing the ocean\n",
      "MODEL PUNCTUATED LINE: \n",
      "  It can be a very complicated thing, the ocean.\n",
      "VALIDATION LINE: \n",
      "  It can be a very complicated thing, the ocean. \n",
      "\n",
      "Modificaciones necesarias:  {('S', 0), ('I', 9), ('I', 7)}\n",
      "Modificaciones hechas por el modelo:  {('S', 0), ('I', 9), ('I', 7)}\n",
      "Diferencias entre modelo y validación:  set() \n",
      "\n",
      "n_hechas (Núm. de modificaciones hechas por el modelo):  3\n",
      "n_correctas (Núm. de modificaciones correctas: \n",
      " interseccion(hechas,necesarias) - error de sustitucion de signo):  3\n",
      "n_necesarias (Núm. de modificaciones necesarias):  3 \n",
      "\n",
      "precision (n_correctas/n_hechas):  1.0\n",
      "recall (n_correctas/n_necesarias):  1.0 \n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Instancia del corpus. Modificar para ver distintos ejemplos.\n",
    "i = 0\n",
    "\n",
    "l = 70\n",
    "print('='*l)\n",
    "print('MODELO 4GRAMS')\n",
    "print('='*l)\n",
    "evaluate_example_from_corpus(addPunctuation4gram, model = model4gram, add_punct_basic=False,corpus_line = i)\n",
    "print('='*l)\n",
    "print('='*l)\n",
    "print('4GRAMS + PUNTUACION BÁSICA')\n",
    "print('='*l)\n",
    "evaluate_example_from_corpus(addPunctuation4gram, model = model4gram, add_punct_basic=True,corpus_line = i)\n",
    "print('='*l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c56a6cb",
   "metadata": {},
   "source": [
    "### APARTADO 5\n",
    "\n",
    "Evaluemos el modelo usando la misma función evaluate() anterior. Vamos a comparar el rendimiento usando también la puntuación básica y sin ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "c01512bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO 4GRAMS\n",
      "=============================================\n",
      "MÉTRICAS\n",
      "=============================================\n",
      "precision global:  0.3060887512899897\n",
      "recall global:  0.04665135738777564\n",
      "F1 global:  0.08096303979909374\n",
      "=============================================\n",
      "precision media:  0.14062073775442538\n",
      "recall medio:  0.049548668299233246\n",
      "F1 medio:  0.07327751014820442\n",
      "=============================================\n",
      "rendimiento:  0.0\n",
      "=============================================\n",
      "número de instancias en el corpus:  14382\n",
      "=============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MODELO 4GRAMS')\n",
    "evaluate(addPunctuation4gram,model=model4gram)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c333949",
   "metadata": {},
   "source": [
    "Podemos ver que este modelo tal cual es muy pobre. Usando la función evaluate_example_from_corpus(), podemos ver que nunca pone la mayúscula inicial como era de esperar y rara vez un punto al final. Además las predicciones parecen bastante pobres y esto se puede deber a la falta de variedad en en las tuplas del corpus de entrenamiento. El corpus debería ser más grande y variado. \n",
    "\n",
    "Veamos la evaluación añadiendo la puntuación básica y lo comparamos con lo obtenido en addPunctuationBasic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "4876526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4GRAMS + PUNTUACION BÁSICA\n",
      "=============================================\n",
      "MÉTRICAS\n",
      "=============================================\n",
      "precision global:  0.7800087656823536\n",
      "recall global:  0.4478750511183114\n",
      "F1 global:  0.5690220215019384\n",
      "=============================================\n",
      "precision media:  0.8431887161340575\n",
      "recall medio:  0.5991128246565686\n",
      "F1 medio:  0.700498694835623\n",
      "=============================================\n",
      "rendimiento:  0.2369628702544848\n",
      "=============================================\n",
      "número de instancias en el corpus:  14382\n",
      "=============================================\n",
      "\n",
      "PUNTUACIÓN BÁSICA\n",
      "=============================================\n",
      "MÉTRICAS\n",
      "=============================================\n",
      "precision global:  0.9481749791028141\n",
      "recall global:  0.4281984334203655\n",
      "F1 global:  0.5899664102286271\n",
      "=============================================\n",
      "precision media:  0.9474342928660826\n",
      "recall medio:  0.5873733513179556\n",
      "F1 medio:  0.7251692521379949\n",
      "=============================================\n",
      "rendimiento:  0.263384786538729\n",
      "=============================================\n",
      "número de instancias en el corpus:  14382\n",
      "=============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('4GRAMS + PUNTUACION BÁSICA')\n",
    "evaluate(addPunctuation4gram,model=model4gram,add_punct_basic=True)\n",
    "print()\n",
    "print('PUNTUACIÓN BÁSICA')\n",
    "evaluate(addPunctuationBasic)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ee6ed",
   "metadata": {},
   "source": [
    "Podemos ver que en general la precisión es más baja en el modelo de 4gramas pero el recall ligeramente superior, pero no de forma sustancial. Además los F1 son menores en el modelo de puntuación básica que en el de 4 gramas así como el rendimiento.\n",
    "\n",
    "En general podemos concluir que el modelo de puntuación básica es mejor que el basado en 4gramas por sorprendente que parezca.\n",
    "\n",
    "Ya que hemos implementado un modelo genérico, vamos a comparar con modelos basados en 3gramas y 5gramas para ver si existe mejoría o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "1df5a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3gram = modelNgram(N=3)\n",
    "model5gram = modelNgram(N=5)\n",
    "model3gram.entrena()\n",
    "model5gram.entrena()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "7c0b5296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3GRAMAS\n",
      "=============================================\n",
      "MÉTRICAS\n",
      "=============================================\n",
      "precision global:  0.7267446209080256\n",
      "recall global:  0.45847620245997045\n",
      "F1 global:  0.5622498481005332\n",
      "=============================================\n",
      "precision media:  0.8039312953739148\n",
      "recall medio:  0.6054353508863484\n",
      "F1 medio:  0.6907051861838088\n",
      "=============================================\n",
      "rendimiento:  0.2259769155889306\n",
      "=============================================\n",
      "número de instancias en el corpus:  14382\n",
      "=============================================\n",
      "\n",
      "5GRAMAS\n",
      "=============================================\n",
      "MÉTRICAS\n",
      "=============================================\n",
      "precision global:  0.8714429298322759\n",
      "recall global:  0.4363930919500456\n",
      "F1 global:  0.5815586484447053\n",
      "=============================================\n",
      "precision media:  0.9020709308151896\n",
      "recall medio:  0.5925814372753306\n",
      "F1 medio:  0.7152840354304869\n",
      "=============================================\n",
      "rendimiento:  0.2533027395355305\n",
      "=============================================\n",
      "número de instancias en el corpus:  14382\n",
      "=============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('3GRAMAS')\n",
    "evaluate(addPunctuationNgram, model = model3gram, add_punct_basic=True)\n",
    "print()\n",
    "print('5GRAMAS')\n",
    "evaluate(addPunctuationNgram, model = model5gram, add_punct_basic=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a06a197",
   "metadata": {},
   "source": [
    "Observamos que en cuanto a precision, el modelo basado en 3gramas es ligeramente inferior al de 4gramas y este a su vez inferior al de 5 gramas, todos por debajo de la precisión del puntuador básico. En cuanto a recall el orden es inverso: el modelo basado en 3 gramas presenta mayor recall que el de 4 y este a su vez que el de 5.\n",
    "En cuanto al F1, los mayores valores los encontramos para el modelo de 5gramas y de puntuación básica. Es obvio que cuanto mayor sea N, menos probable es la probabilidad de que se de una N-tupla concreta por lo que el modelo basado en N-gramas con N grande coincidirá eventualmente con el de puntuación básica si se considera el parámetro add_punct_basic.\n",
    "\n",
    "Para acabar este apartado podemos explorar algunas predicciones de los modelos de 3 y 5 gramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "4a10a707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODELO 3GRAMS\n",
      "======================================================================\n",
      "TEST LINE: \n",
      "  it can be a very complicated thing the ocean\n",
      "MODEL PUNCTUATED LINE: \n",
      "  It can be a very complicated thing. The ocean.\n",
      "VALIDATION LINE: \n",
      "  It can be a very complicated thing, the ocean. \n",
      "\n",
      "Modificaciones necesarias:  {('S', 0), ('I', 9), ('I', 7)}\n",
      "Modificaciones hechas por el modelo:  {('S', 0), ('I', 9), ('S', 7), ('I', 7)}\n",
      "Diferencias entre modelo y validación:  {('S', 7), ('S', 8)} \n",
      "\n",
      "n_hechas (Núm. de modificaciones hechas por el modelo):  4\n",
      "n_correctas (Núm. de modificaciones correctas: \n",
      " interseccion(hechas,necesarias) - error de sustitucion de signo):  2\n",
      "n_necesarias (Núm. de modificaciones necesarias):  3 \n",
      "\n",
      "precision (n_correctas/n_hechas):  0.5\n",
      "recall (n_correctas/n_necesarias):  0.6666666666666666 \n",
      "\n",
      "======================================================================\n",
      "MODELO 5GRAMS\n",
      "======================================================================\n",
      "TEST LINE: \n",
      "  it can be a very complicated thing the ocean\n",
      "MODEL PUNCTUATED LINE: \n",
      "  It can be a very complicated thing, the ocean.\n",
      "VALIDATION LINE: \n",
      "  It can be a very complicated thing, the ocean. \n",
      "\n",
      "Modificaciones necesarias:  {('S', 0), ('I', 9), ('I', 7)}\n",
      "Modificaciones hechas por el modelo:  {('S', 0), ('I', 9), ('I', 7)}\n",
      "Diferencias entre modelo y validación:  set() \n",
      "\n",
      "n_hechas (Núm. de modificaciones hechas por el modelo):  3\n",
      "n_correctas (Núm. de modificaciones correctas: \n",
      " interseccion(hechas,necesarias) - error de sustitucion de signo):  3\n",
      "n_necesarias (Núm. de modificaciones necesarias):  3 \n",
      "\n",
      "precision (n_correctas/n_hechas):  1.0\n",
      "recall (n_correctas/n_necesarias):  1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instancia del corpus. Modificar para ver distintos ejemplos.\n",
    "i= 0\n",
    "\n",
    "l = 70 \n",
    "print('='*l)\n",
    "print('MODELO 3GRAMS')\n",
    "print('='*l)\n",
    "evaluate_example_from_corpus(addPunctuationNgram, model = model3gram, add_punct_basic=True,corpus_line = i)\n",
    "print('='*l)\n",
    "print('MODELO 5GRAMS')\n",
    "print('='*l)\n",
    "evaluate_example_from_corpus(addPunctuationNgram, model = model5gram, add_punct_basic=True,corpus_line = i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3633a0",
   "metadata": {},
   "source": [
    "### APARTADO 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
